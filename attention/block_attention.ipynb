{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed56632-4ef9-4e84-ba5f-afa567899c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as F\n",
    "from typing import Union\n",
    "from functools import lru_cache\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7adf38c-82ba-449e-8406-fd46c00f0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters : \n",
    "\n",
    "batch_size = 1\n",
    "seq_length = 8192\n",
    "num_attention_heads = 20\n",
    "hidden_size = 1280\n",
    "attention_head_size = int(hidden_size / num_attention_heads)\n",
    "all_head_size = num_attention_heads * attention_head_size\n",
    "\n",
    "position_embedding_type = \"rotary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0593d1b-f665-4b09-b226-104885e3d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize layers : \n",
    "\n",
    "query_layer = nn.Linear(hidden_size, all_head_size)\n",
    "key_layer = nn.Linear(hidden_size, all_head_size)\n",
    "value_layer = nn.Linear(hidden_size, all_head_size)\n",
    "\n",
    "dropout_layer = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcfc9e1-ad1c-4978-b644-4d20970d3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement RoPE : \n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    cos = cos[:, :, : x.shape[-2], :]\n",
    "    sin = sin[:, :, : x.shape[-2], :]\n",
    "    return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "class RotaryEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary position embeddings based on those in\n",
    "    [RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer). Query and keys are transformed by rotation\n",
    "    matrices which depend on their relative positions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        # Generate and save the inverse frequency buffer (non trainable)\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
    "        inv_freq = inv_freq\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        self._seq_len_cached = None\n",
    "        self._cos_cached = None\n",
    "        self._sin_cached = None\n",
    "\n",
    "    def _update_cos_sin_tables(self, x, seq_dimension=2):\n",
    "        seq_len = x.shape[seq_dimension]\n",
    "\n",
    "        # Reset the tables if the sequence length has changed,\n",
    "        # or if we're on a new device (possibly due to tracing for instance)\n",
    "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
    "            self._seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq)\n",
    "            freqs = torch.outer(t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
    "\n",
    "            self._cos_cached = emb.cos()[None, None, :, :]\n",
    "            self._sin_cached = emb.sin()[None, None, :, :]\n",
    "\n",
    "        return self._cos_cached, self._sin_cached\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
    "\n",
    "        return (\n",
    "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
    "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0552b2-fdb1-4372-a2ce-a1c625d00b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose for attentions :\n",
    "\n",
    "def transpose_for_scores(x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292b7e9d-691a-44a2-9c1e-af0cbdfbeeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192, 1280])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn((1, seq_length, hidden_size))\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d79b95-8b70-4a2a-b849-40e8c453df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192, 1280])\n",
      "torch.Size([1, 20, 8192, 64])\n"
     ]
    }
   ],
   "source": [
    "# Query :\n",
    "\n",
    "mixed_query_layer = query_layer(hidden_states)\n",
    "print(mixed_query_layer.shape)\n",
    "query = transpose_for_scores(mixed_query_layer)\n",
    "query = query * attention_head_size**-0.5\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0ad8ea-3922-46a3-b1c7-7710bcf82f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key, Value :\n",
    "\n",
    "key = key_layer(hidden_states)\n",
    "key = transpose_for_scores(key)\n",
    "\n",
    "value = value_layer(hidden_states)\n",
    "value = transpose_for_scores(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22f7e70-9994-4591-b124-0f9ed3a0dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding : \n",
    "\n",
    "if position_embedding_type == \"rotary\":\n",
    "    rotary_embeddings = RotaryEmbedding(attention_head_size)\n",
    "    query, key = rotary_embeddings(query, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f138f50-402b-4b94-a509-69e460f66d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for full matmul : 4.358472108840942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 8192, 8192])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication for attention scores :\n",
    "#tmean = []\n",
    "#for _ in range(0, 1) : \n",
    "start_time = time.time()\n",
    "attention_scores_full = torch.matmul(query, key.transpose(-1, -2))\n",
    "print(f'Elapsed time for full matmul : {time.time()-start_time}')\n",
    "#tmean.append(time.time()-start_time)\n",
    "attention_scores_full.shape\n",
    "\n",
    "#print(sum(tmean)/len(tmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e46d2ce-64c2-4886-8e7d-bc39a7040917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mask : \n",
    "\n",
    "attention_mask_full = None\n",
    "if attention_mask_full is not None:\n",
    "    # Apply the attention mask is (precomputed for all layers in EsmModel forward() function)\n",
    "    attention_mask_full = attention_mask_full\n",
    "    attention_scores_full = attention_scores_full + attention_mask_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "473890b2-c3a1-4b27-b353-8a4edc51fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations before Att*V : \n",
    "\n",
    "attention_probs_full = nn.functional.softmax(attention_scores_full, dim=-1)\n",
    "attention_probs_full = dropout_layer(attention_probs_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb0d7bdb-571a-4e73-9ad4-960a3edcb256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for context layer matmul : 7.70710301399231\n",
      "torch.Size([1, 8192, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Context layer :\n",
    "t=time.time()\n",
    "context = torch.matmul(attention_probs_full, value)\n",
    "print(f'Elapsed time for context layer matmul : {time.time()-t}')\n",
    "context_layer = context.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "new_context_layer_shape = context_layer.size()[:-2] + (all_head_size,)\n",
    "context_layer = context_layer.view(new_context_layer_shape)\n",
    "print(context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e02ae2c5-fdac-402b-972f-f2eeed5fdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "output_attentions = True\n",
    "outputs = (context_layer, attention_probs_full) if output_attentions else (context_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02007968-0b02-4d92-8659-228e8ed68b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8192, 1280]), torch.Size([1, 20, 8192, 8192]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62697fd6-640a-47c8-ae36-018ef6eb5e79",
   "metadata": {},
   "source": [
    "Proteins blocks attentions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1cbf920-5056-4343-bbdc-03c7e3bbd54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "330\n",
      "2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input : hidden states + sequence information (proteins + interactions map)\n",
    "\n",
    "# Random proteins information : \n",
    "def generate_list(n, Amin, Amax):\n",
    "    ni_list = []\n",
    "    remaining = n\n",
    "    while remaining > Amin:\n",
    "        ni = random.randint(Amin, min(Amax, remaining))\n",
    "        ni_list.append(ni)\n",
    "        remaining -= ni\n",
    "    ni_list.append(remaining)\n",
    "    return ni_list\n",
    "\n",
    "# Random proteins interactions : \n",
    "def generate_couples(n_couples, n_len):\n",
    "    couples = []\n",
    "    while len(couples) < n_couples :\n",
    "        i = random.randint(0, n_len - 1)\n",
    "        j = random.randint(0, n_len - 1)\n",
    "        if abs(i - j) > 1 and (i, j) not in couples and (j, i) not in couples:\n",
    "            couples.append((i, j))\n",
    "    return couples\n",
    "\n",
    "proteins_sizes = generate_list(seq_length, Amin = 51, Amax = 200) \n",
    "proteins_cs =  [0]+list(np.cumsum(np.array(proteins_sizes)))\n",
    "n = len(proteins_sizes)\n",
    "print(n)\n",
    "proteins_interactions = generate_couples(n_couples = 5 * n, n_len = n) # Max number of couples : n * (n - 3) / 2\n",
    "sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "print(len(proteins_interactions)), print(int(n * (n - 3) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5051b0-4a0c-425f-ae62-71c93f081ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide k, q, v based on block_size : \n",
    "\n",
    "def reshape_tensor(tensor, proteins_sizes, block_size):\n",
    "    _, seq_len, hidden_dim = tensor.shape\n",
    "    sub_blocks = []\n",
    "    start_index = 0\n",
    "\n",
    "    for size in proteins_sizes:\n",
    "        num_full_blocks = size // block_size  # Nombre de sous-blocs entiers\n",
    "        end_index = start_index + num_full_blocks * block_size  # Index de fin pour les sous-blocs entiers\n",
    "        if num_full_blocks > 0:\n",
    "            sub_blocks.append(tensor[0][start_index:end_index].reshape(num_full_blocks * block_size, hidden_dim))\n",
    "        start_index += size\n",
    "            \n",
    "    if sub_blocks:\n",
    "        result_tensor = torch.cat(sub_blocks, dim=0)\n",
    "        \n",
    "    return result_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa25ea3-daad-4a6e-b27d-5c174be7552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide interactions in blocks : \n",
    "\n",
    "block_size = 50\n",
    "\n",
    "def chunk_proteins(sorted_proteins_interactions, proteins_lengths, block_size):\n",
    "    # Calculer le nombre complet de blocs pour chaque protéine\n",
    "    num_blocks = [length // block_size for length in proteins_lengths]\n",
    "\n",
    "    # Cumulative sum pour obtenir les indices de début pour chaque protéine dans la grille globale\n",
    "    num_blocks_cs = np.cumsum([0] + num_blocks).tolist()\n",
    "    index = 0\n",
    "    chunked_blocks = []\n",
    "    \n",
    "    for h in num_blocks : \n",
    "        for j in range(h) : \n",
    "            chunked_blocks.append(index)\n",
    "            index +=1\n",
    "    block_interactions = []\n",
    "              \n",
    "    for i, j in sorted_proteins_interactions:\n",
    "        for k in range(num_blocks[i]):\n",
    "            num_blocks_cs[i] + k\n",
    "            for h in range(num_blocks[j]):\n",
    "                block_interactions.append((num_blocks_cs[i] + k, num_blocks_cs[j] + h))\n",
    "\n",
    "    return block_interactions, chunked_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d35343de-8c7c-4828-b70f-465d40ca48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_crows(rows, n): \n",
    "    rows = np.array(rows)\n",
    "    counts = np.bincount(rows, minlength=n+1)\n",
    "    \n",
    "    # Si le tableau résultant est plus court que n+1, on ajoute des zéros à la fin\n",
    "    if counts.size < n+1:\n",
    "        counts = np.pad(counts, (0, n+1-counts.size), constant_values=0)\n",
    "    counts_cs = np.cumsum(counts)\n",
    "    return counts_cs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "748b424b-13e7-4e0e-8bed-f8fd35ab67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_attention_matrix(query, key, proteins_interactions, proteins_cs, proteins_list, block_size):\n",
    "    batch_size, num_heads, seq_len, all_head_size = query.shape\n",
    "    start_time = time.time()\n",
    "    attentions = []\n",
    "    block_positions = []\n",
    "    sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "    \n",
    "    for i, j in sorted_proteins_interactions :\n",
    "        # Blocks\n",
    "        query_block = query[:, :, proteins_cs[i]:proteins_cs[i+1], :]\n",
    "        key_block = key[:, :, proteins_cs[j]:proteins_cs[j+1], :]\n",
    "        \n",
    "        # Compute attention matrix for the 2 blocks\n",
    "        attention_block = torch.matmul(query_block, key_block.transpose(-1, -2)).squeeze()\n",
    "        attentions.append(attention_block) \n",
    "\n",
    "    amc = time.time()-start_time\n",
    "\n",
    "    # Create block sparse matrix with torch.sparse_bsr_tensor\n",
    "    \n",
    "    # columns and rows : \n",
    "    t2 = time.time()\n",
    "    col_indices = [x[1] for x in sorted_proteins_interactions]\n",
    "    rows = [x[0] for x in sorted_proteins_interactions]\n",
    "    crow_indices = [0] + rows_to_crows(rows, len(proteins_cs) - 1)[:-1]\n",
    "    crow_tensor = torch.stack([torch.tensor(crow_indices)] * 20)\n",
    "    col_tensor = torch.stack([torch.tensor(col_indices)] * 20)\n",
    "\n",
    "    # values :    \n",
    "    concatenated_attentions = torch.stack(attentions, dim=1)\n",
    "\n",
    "    #sparse_matrix = create_sparse_coo_with_variable_blocks(attentions, block_positions, seq_len, seq_len)\n",
    "    sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [num_heads, len(proteins_list)*block_size, len(proteins_list)*block_size])\n",
    "    smc = time.time() - t2\n",
    "    \n",
    "    return sparse_matrix, amc, smc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0850593-79fc-4137-85d1-fc3c5233edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Query, Key, Value chunked by block_size\n",
    "block_size = 50\n",
    "\n",
    "chunked_hidden_states = reshape_tensor(hidden_states, proteins_sizes, block_size)\n",
    "print(hidden_states.shape)\n",
    "chunked_mixed_query_layer = query_layer(chunked_hidden_states)\n",
    "chunked_query = transpose_for_scores(chunked_mixed_query_layer)\n",
    "chunked_query = chunked_query * attention_head_size**-0.5\n",
    "\n",
    "chunked_key = key_layer(chunked_hidden_states)\n",
    "chunked_key = transpose_for_scores(chunked_key)\n",
    "\n",
    "chunked_value = value_layer(chunked_hidden_states)\n",
    "chunked_value = transpose_for_scores(chunked_value).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f948d8b3-f115-4e50-b54d-b7626a8b9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_interactions, chunked_blocks = chunk_proteins(sorted_proteins_interactions, proteins_sizes, block_size)\n",
    "proteins_chunked_sizes = [block_size for _ in chunked_blocks]\n",
    "proteins_chunked_cs =  [0]+list(np.cumsum(np.array(proteins_chunked_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92d55b18-0b10-4109-9c86-f9e57f712484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/4km91tb53796gmtpqmv98nbr0000gn/T/ipykernel_28093/1048404363.py:33: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [num_heads, len(proteins_list)*block_size, len(proteins_list)*block_size])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 6600, 6600])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_sparse_matrix, attention_time, matrix_time = sparse_attention_matrix(chunked_query, chunked_key, chunked_interactions, proteins_chunked_cs, proteins_chunked_sizes, block_size)\n",
    "chunked_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c7dfcd3-7f3b-49c9-a2ba-3641935bb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_bsr_dropout(x, p, training):\n",
    "    values = x.values()  \n",
    "    dropped_values = F.dropout(values, p=p, training=training)  \n",
    "    new_sparse_tensor = torch.sparse_bsr_tensor(x.crow_indices(), x.col_indices(), dropped_values, size=x.size())\n",
    "    return new_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e034677f-579c-4b2a-9bf8-16d86f4a594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.sparse._triton_ops import bsr_softmax # Only supported by CUDA and Triton ? \n",
    "\n",
    "# chunked_sparse_probs = bsr_softmax(chunked_sparse_matrix, dim=-1)\n",
    "chunked_sparse_probs = sparse_bsr_dropout(chunked_sparse_matrix, 0.1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1adbd26-90b4-4c11-8147-3e984187ee6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tv \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      2\u001b[0m batch_context \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chunked_value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "tv = time.time()\n",
    "batch_context = []\n",
    "for batch in range(chunked_value.shape[0]):\n",
    "    chunked_context = torch.sparse.mm(chunked_sparse_probs[batch], chunked_value[batch])\n",
    "    batch_context.append(chunked_context)\n",
    "    \n",
    "chunked_context = torch.stack(batch_context, dim=0).unsqueeze(0)\n",
    "print(f'Elapsed time for context layer matmul : {time.time()-tv}')\n",
    "# Only way to perform batched matmul between sparse tensor and dense tensor (bmm sparse not implemented yet) - max : dim = 2 * dim = 2\n",
    "\n",
    "print(chunked_context.shape)\n",
    "\n",
    "chunked_context_layer = chunked_context.permute(0, 2, 1, 3).contiguous()\n",
    "new_chunked_context_layer_shape = chunked_context_layer.size()[:-2] + (all_head_size,)\n",
    "chunked_context_layer = chunked_context_layer.view(new_chunked_context_layer_shape)\n",
    "print(chunked_context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c464636-f8a3-452b-91dd-bedca0957446",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_sizes_eval = [i for i in range(2, 101, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b332775-512b-465a-8ad4-d9498a41a21f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m proteins_chunked_sizes \u001b[38;5;241m=\u001b[39m [block_size \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m chunked_blocks]\n\u001b[1;32m     29\u001b[0m proteins_chunked_cs \u001b[38;5;241m=\u001b[39m  [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mcumsum(np\u001b[38;5;241m.\u001b[39marray(proteins_chunked_sizes)))\n\u001b[0;32m---> 31\u001b[0m chunked_sparse_matrix, attention_time, matrix_time \u001b[38;5;241m=\u001b[39m \u001b[43msparse_attention_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunked_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_interactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproteins_chunked_cs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproteins_chunked_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m chunked_sparse_probs \u001b[38;5;241m=\u001b[39m sparse_bsr_dropout(chunked_sparse_matrix, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m batch_context \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[50], line 10\u001b[0m, in \u001b[0;36msparse_attention_matrix\u001b[0;34m(query, key, proteins_interactions, proteins_cs, proteins_list, block_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m sorted_proteins_interactions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(proteins_interactions, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m sorted_proteins_interactions :\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Blocks\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     query_block \u001b[38;5;241m=\u001b[39m query[:, :, proteins_cs[i]:proteins_cs[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], :]\n\u001b[1;32m     11\u001b[0m     key_block \u001b[38;5;241m=\u001b[39m key[:, :, proteins_cs[j]:proteins_cs[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], :]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Compute attention matrix for the 2 blocks\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TO RUN TO EVALUATE BLOCK_SIZE (very slow for 2 - start higher ?)\n",
    "\n",
    "attention_times = []\n",
    "sparse_matrix_creation_times = []\n",
    "total_times = []\n",
    "zero_values = []\n",
    "for block_size in blocks_sizes_eval : \n",
    "    attention_times_mean = []\n",
    "    sparse_matrix_creation_times_mean = []\n",
    "    total_times_mean = []\n",
    "    zero_values_mean = []\n",
    "    for s in range(1, 5) : \n",
    "        tt = time.time()\n",
    "        chunked_hidden_states = reshape_tensor(hidden_states, proteins_sizes, block_size)\n",
    "        \n",
    "        chunked_mixed_query_layer = query_layer(chunked_hidden_states)\n",
    "        chunked_query = transpose_for_scores(chunked_mixed_query_layer)\n",
    "        chunked_query = chunked_query * attention_head_size**-0.5\n",
    "        \n",
    "        chunked_key = key_layer(chunked_hidden_states)\n",
    "        chunked_key = transpose_for_scores(chunked_key)\n",
    "        \n",
    "        chunked_value = value_layer(chunked_hidden_states)\n",
    "        chunked_value = transpose_for_scores(chunked_value).squeeze()\n",
    "    \n",
    "        chunked_interactions, chunked_blocks = chunk_proteins(sorted_proteins_interactions, proteins_sizes, block_size)\n",
    "        proteins_chunked_sizes = [block_size for _ in chunked_blocks]\n",
    "        proteins_chunked_cs =  [0]+list(np.cumsum(np.array(proteins_chunked_sizes)))\n",
    "    \n",
    "        chunked_sparse_matrix, attention_time, matrix_time = sparse_attention_matrix(chunked_query, chunked_key, chunked_interactions, proteins_chunked_cs, proteins_chunked_sizes, block_size)\n",
    "\n",
    "        \n",
    "        chunked_sparse_probs = sparse_bsr_dropout(chunked_sparse_matrix, 0.1, True)\n",
    "    \n",
    "        batch_context = []\n",
    "        for batch in range(chunked_value.shape[0]):\n",
    "            chunked_context = torch.sparse.mm(chunked_sparse_probs[batch], chunked_value[batch])\n",
    "            batch_context.append(chunked_context)\n",
    "            \n",
    "        chunked_context = torch.stack(batch_context, dim=0).unsqueeze(0)\n",
    "    \n",
    "        chunked_context_layer = chunked_context.permute(0, 2, 1, 3).contiguous()\n",
    "        new_chunked_context_layer_shape = chunked_context_layer.size()[:-2] + (all_head_size,)\n",
    "        chunked_context_layer = chunked_context_layer.view(new_chunked_context_layer_shape)\n",
    "    \n",
    "        output_attentions = True\n",
    "        outputs = (chunked_context_layer, chunked_sparse_probs) if output_attentions else (chunked_context_layer,)\n",
    "        ft = time.time()-tt\n",
    "        nv = seq_length - chunked_hidden_states.shape[1]\n",
    "\n",
    "        attention_times_mean.append(attention_time)\n",
    "        sparse_matrix_creation_times_mean.append(matrix_time)\n",
    "        total_times_mean.append(ft)\n",
    "        zero_values_mean.append(nv)\n",
    "        print(zero_values_mean)\n",
    "\n",
    "    zero_values.append(sum(zero_values_mean)/len(zero_values_mean))\n",
    "    attention_times.append(sum(attention_times_mean)/len(attention_times_mean))\n",
    "    sparse_matrix_creation_times.append(sum(sparse_matrix_creation_times_mean)/len(sparse_matrix_creation_times_mean))\n",
    "    total_times.append(sum(total_times_mean)/len(total_times_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2544cd4-458d-4989-b03f-d8e643a0e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('/home/thibaut/blocks_sizes_8192.pickle', 'wb') as fichier0:\n",
    "    pickle.dump(blocks_sizes_eval, fichier0)\n",
    "\n",
    "with open('/home/thibaut/attention_times_8192.pickle', 'wb') as fichier1:\n",
    "    pickle.dump(attention_times, fichier1)\n",
    "\n",
    "with open('/home/thibaut/matrix_times_8192.pickle', 'wb') as fichier2:\n",
    "    pickle.dump(sparse_matrix_creation_times, fichier2)\n",
    "\n",
    "with open('/home/thibaut/global_times_8192.pickle', 'wb') as fichier3:\n",
    "    pickle.dump(total_times, fichier3)\n",
    "\n",
    "with open('/home/thibaut/zero_values_8192.pickle', 'wb') as fichier4:\n",
    "    pickle.dump(zero_values, fichier4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acac22b-67e7-42f7-877d-ec789db71532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
