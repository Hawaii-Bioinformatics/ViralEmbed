{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89860edc-2ae3-4914-8fa1-7658ea69da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EsmForTokenClassification, EsmForMaskedLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce7c2ef-ddab-4e16-a8bd-93fd0248420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as F\n",
    "from typing import Union\n",
    "from functools import lru_cache\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "809753d7-c7ae-4b23-aed4-abb46106007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters : \n",
    "\n",
    "batch_size = 1\n",
    "seq_length = 4096\n",
    "num_attention_heads = 20\n",
    "hidden_size = 1280\n",
    "attention_head_size = int(hidden_size / num_attention_heads)\n",
    "all_head_size = num_attention_heads * attention_head_size\n",
    "\n",
    "position_embedding_type = \"rotary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169f8de5-ab7a-4ab3-9029-24b95add0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize layers : \n",
    "\n",
    "query_layer = nn.Linear(hidden_size, all_head_size)\n",
    "key_layer = nn.Linear(hidden_size, all_head_size)\n",
    "value_layer = nn.Linear(hidden_size, all_head_size)\n",
    "\n",
    "dropout_layer = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "593db5d0-a4fa-4fd5-9c3a-4797c4adfdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1280)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_layer.in_features, query_layer.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faed820a-1369-44fa-b1dc-34a885afe189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement RoPE : \n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    cos = cos[:, :, : x.shape[-2], :]\n",
    "    sin = sin[:, :, : x.shape[-2], :]\n",
    "    return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "class RotaryEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary position embeddings based on those in\n",
    "    [RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer). Query and keys are transformed by rotation\n",
    "    matrices which depend on their relative positions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        # Generate and save the inverse frequency buffer (non trainable)\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
    "        inv_freq = inv_freq\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        self._seq_len_cached = None\n",
    "        self._cos_cached = None\n",
    "        self._sin_cached = None\n",
    "\n",
    "    def _update_cos_sin_tables(self, x, seq_dimension=2):\n",
    "        seq_len = x.shape[seq_dimension]\n",
    "\n",
    "        # Reset the tables if the sequence length has changed,\n",
    "        # or if we're on a new device (possibly due to tracing for instance)\n",
    "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
    "            self._seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq)\n",
    "            freqs = torch.outer(t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
    "\n",
    "            self._cos_cached = emb.cos()[None, None, :, :]\n",
    "            self._sin_cached = emb.sin()[None, None, :, :]\n",
    "\n",
    "        return self._cos_cached, self._sin_cached\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
    "\n",
    "        return (\n",
    "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
    "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21b9f27-1acc-4f6e-bdc2-8346bf2e280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose for attentions :\n",
    "\n",
    "def transpose_for_scores(x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d622cac-31e5-4ddf-a5f8-436300b31e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = torch.randn((1, seq_length, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "043756c8-5661-43bd-812f-5d684666a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096, 1280])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b628fdf7-3ca9-4ea4-ada5-19014a30d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 1280])\n",
      "torch.Size([1, 20, 4096, 64])\n"
     ]
    }
   ],
   "source": [
    "# Query :\n",
    "\n",
    "mixed_query_layer = query_layer(hidden_states)\n",
    "print(mixed_query_layer.shape)\n",
    "query = transpose_for_scores(mixed_query_layer)\n",
    "print(query.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6997e43c-86c6-4d7e-88ce-46f3ff3f63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query * attention_head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fad19ab-b867-4d05-9eac-90b9c673e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key, Value :\n",
    "\n",
    "key = key_layer(hidden_states)\n",
    "key = transpose_for_scores(key)\n",
    "\n",
    "value = value_layer(hidden_states)\n",
    "value = transpose_for_scores(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34de12d2-99b1-4b1a-923d-72958c65fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding : \n",
    "\n",
    "if position_embedding_type == \"rotary\":\n",
    "    rotary_embeddings = RotaryEmbedding(attention_head_size)\n",
    "    query, key = rotary_embeddings(query, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a26d1b16-83f2-4f81-bc14-e551fcc17a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 4096, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de0cc2b3-1a70-403b-bc3a-7579c0bafcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for full matmul : 0.7023530006408691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 4096, 4096])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication for attention scores :\n",
    "\n",
    "start_time = time.time()\n",
    "attention_scores_full = torch.matmul(query, key.transpose(-1, -2))\n",
    "print(f'Elapsed time for full matmul : {time.time()-start_time}')\n",
    "attention_scores_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4da35d0f-c737-4e81-91b0-e4f3a2f8ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mask : \n",
    "\n",
    "attention_mask_full = None\n",
    "if attention_mask_full is not None:\n",
    "    # Apply the attention mask is (precomputed for all layers in EsmModel forward() function)\n",
    "    attention_mask_full = attention_mask_full\n",
    "    attention_scores_full = attention_scores_full + attention_mask_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2e4f480-1ca5-438d-8657-915eb2b7796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations before Att*V : \n",
    "\n",
    "attention_probs_full = nn.functional.softmax(attention_scores_full, dim=-1)\n",
    "attention_probs_full = dropout_layer(attention_probs_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7cbf5d1-8224-4090-b5bd-97ae1b2d4af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Context layer :\n",
    "\n",
    "context = torch.matmul(attention_probs_full, value)\n",
    "context_layer = context.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "new_context_layer_shape = context_layer.size()[:-2] + (all_head_size,)\n",
    "context_layer = context_layer.view(new_context_layer_shape)\n",
    "print(context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a805dafb-20be-46bd-8672-0c4a8f0a88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "output_attentions = True\n",
    "outputs = (context_layer, attention_probs_full) if output_attentions else (context_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2007fe35-58fe-45a4-a735-a926437386fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096, 1280]), torch.Size([1, 20, 4096, 4096]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3c9da5b-f965-4181-b027-1440b28cabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025cb79-5f59-4f89-9dce-1d4e99b35875",
   "metadata": {},
   "source": [
    "Longformer Attention (sliding window) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d18e8bf2-2bae-4f26-a928-98e42a8a6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers transformations methods : \n",
    "\n",
    "def _skew(x, direction, padding_value):\n",
    "    '''Convert diagonals into columns (or columns into diagonals depending on `direction`'''\n",
    "    x_padded = F.pad(x, direction, value=padding_value)\n",
    "    x_padded = x_padded.view(*x_padded.size()[:-2], x_padded.size(-1), x_padded.size(-2))\n",
    "    return x_padded\n",
    "\n",
    "def _skew2(x, padding_value):\n",
    "    '''shift every row 1 step to right converting columns into diagonals'''\n",
    "    # X = B x C x M x L\n",
    "    B, C, M, L = x.size()\n",
    "    x = F.pad(x, (0, M + 1), value=padding_value)  # B x C x M x (L+M+1)\n",
    "    x = x.view(B, C, -1)  # B x C x ML+MM+M\n",
    "    x = x[:, :, :-M]  # B x C x ML+MM\n",
    "    x = x.view(B, C, M, M + L)  # B x C, M x L+M\n",
    "    x = x[:, :, :, :-1]\n",
    "    return x\n",
    "\n",
    "def _chunk(x, w):\n",
    "    dim = int(x.size(1) // (w * 2))\n",
    "    x = x.view(x.size(0), dim, int(w * 2), x.size(2))\n",
    "\n",
    "    chunk_size = list(x.size())\n",
    "    chunk_size[1] = chunk_size[1] * 2 - 1\n",
    "\n",
    "    chunk_stride = list(x.stride())\n",
    "    chunk_stride[1] = chunk_stride[1] // 2\n",
    "    \n",
    "    return x.as_strided(size=chunk_size, stride=chunk_stride)\n",
    "\n",
    "@lru_cache()\n",
    "def _get_invalid_locations_mask(w: int, d: Union[torch.Tensor,int], autoregressive: bool, device: str):\n",
    "    if isinstance(d, int):\n",
    "        affected_seq_len = w * d\n",
    "        mask = _get_invalid_locations_mask_fixed_dilation(affected_seq_len, w, d)\n",
    "        mask = mask[None, :, None, :]\n",
    "    else:\n",
    "        affected_seq_len = w * d.max()\n",
    "        head_masks = []\n",
    "        d_list = d.cpu().numpy().tolist()\n",
    "        for d in d_list:\n",
    "            one_head_mask = _get_invalid_locations_mask_fixed_dilation(affected_seq_len, w, d)\n",
    "            head_masks.append(one_head_mask)\n",
    "        mask = torch.stack(head_masks, dim=-2)\n",
    "        mask = mask[None, :, :, :]\n",
    "\n",
    "    ending_mask = None if autoregressive else mask.flip(dims=(1, 3)).bool().to(device)\n",
    "    return affected_seq_len, mask.bool().to(device), ending_mask\n",
    "\n",
    "def _get_invalid_locations_mask_fixed_dilation(seq_len: int, w: int, d: int):\n",
    "    diagonals_list = []\n",
    "    for j in range(-d * w, d, d):\n",
    "        diagonal_mask = torch.zeros(seq_len, device='cpu', dtype=torch.uint8)\n",
    "        diagonal_mask[:-j] = 1\n",
    "        diagonals_list.append(diagonal_mask)\n",
    "    return torch.stack(diagonals_list, dim=-1)\n",
    "\n",
    "def mask_invalid_locations(input_tensor: torch.Tensor, w: int, d: Union[torch.Tensor, int], autoregressive: bool) -> torch.Tensor:\n",
    "    affected_seq_len, beginning_mask, ending_mask = _get_invalid_locations_mask(w, d, autoregressive, input_tensor.device)\n",
    "    seq_len = input_tensor.size(1)\n",
    "    beginning_input = input_tensor[:, :affected_seq_len, :, :w+1]\n",
    "    beginning_mask = beginning_mask[:, :seq_len].expand(beginning_input.size())\n",
    "    beginning_input.masked_fill_(beginning_mask, -float('inf'))\n",
    "    if not autoregressive:\n",
    "        ending_input = input_tensor[:, -affected_seq_len:, :, -(w+1):]\n",
    "        ending_mask = ending_mask[:, -seq_len:].expand(ending_input.size())\n",
    "        ending_input.masked_fill_(ending_mask, -float('inf'))\n",
    "\n",
    "def sliding_chunks_matmul_qk(q: torch.Tensor, k: torch.Tensor, w: int, padding_value: float):\n",
    "\n",
    "    bsz, num_heads,seqlen, head_dim = q.size()\n",
    "\n",
    "    assert seqlen % (w * 2) == 0\n",
    "    assert q.size() == k.size()\n",
    "\n",
    "    chunks_count = seqlen // w - 1\n",
    "\n",
    "    # group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size w * 2\n",
    "    q = q.reshape(bsz * num_heads, seqlen, head_dim)\n",
    "    k = k.reshape(bsz * num_heads, seqlen, head_dim)\n",
    "\n",
    "    chunk_q = _chunk(q, w)\n",
    "    chunk_k = _chunk(k, w)\n",
    "    chunk_attn = torch.einsum('bcxd,bcyd->bcxy', (chunk_q, chunk_k))  # multiply\n",
    "\n",
    "    # convert diagonals into columns\n",
    "    diagonal_chunk_attn = _skew(chunk_attn, direction=(0, 0, 0, 1), padding_value=padding_value)\n",
    "    diagonal_attn = diagonal_chunk_attn.new_empty((bsz * num_heads, chunks_count + 1, w, w * 2 + 1))\n",
    "    \n",
    "    diagonal_attn[:, :-1, :, w:] = diagonal_chunk_attn[:, :, :w, :w + 1]\n",
    "    diagonal_attn[:, -1, :, w:] = diagonal_chunk_attn[:, -1, w:, :w + 1]\n",
    "    # - copying the lower triangle\n",
    "    diagonal_attn[:, 1:, :, :w] = diagonal_chunk_attn[:, :, - (w + 1):-1, w + 1:]\n",
    "    diagonal_attn[:, 0, 1:w, 1:w] = diagonal_chunk_attn[:, 0, :w - 1, 1 - w:]\n",
    "\n",
    "    # separate bsz and num_heads dimensions again\n",
    "    diagonal_attn = diagonal_attn.view(bsz, num_heads, seqlen, 2 * w + 1)\n",
    "    mask_invalid_locations(diagonal_attn, w, 1, True)\n",
    "\n",
    "    return diagonal_attn\n",
    "\n",
    "def sliding_chunks_matmul_pv(prob: torch.Tensor, v: torch.Tensor, w: int):\n",
    "    \n",
    "    bsz, num_heads,seqlen, head_dim = v.size()\n",
    "    assert seqlen % (w * 2) == 0\n",
    "    assert prob.size()[:3] == v.size()[:3]\n",
    "    assert prob.size(3) == 2 * w + 1\n",
    "    chunks_count = seqlen // w - 1\n",
    "    # group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size 2w\n",
    "    chunk_prob = prob.reshape(bsz * num_heads, seqlen // w, w, 2 * w + 1)\n",
    "\n",
    "    # group bsz and num_heads dimensions into one\n",
    "    v = v.reshape(bsz * num_heads, seqlen, head_dim)\n",
    "\n",
    "    # pad seqlen with w at the beginning of the sequence and another w at the end\n",
    "    padded_v = F.pad(v, (0, 0, w, w), value=-1)\n",
    "\n",
    "    # chunk padded_v into chunks of size 3w and an overlap of size w\n",
    "    chunk_v_size = (bsz * num_heads, chunks_count + 1, 3 * w, head_dim)\n",
    "    chunk_v_stride = padded_v.stride()\n",
    "    chunk_v_stride = chunk_v_stride[0], w * chunk_v_stride[1], chunk_v_stride[1], chunk_v_stride[2]\n",
    "    chunk_v = padded_v.as_strided(size=chunk_v_size, stride=chunk_v_stride)\n",
    "\n",
    "    skewed_prob = _skew2(chunk_prob, padding_value=0)\n",
    "    context = torch.einsum('bcwd,bcdh->bcwh', (skewed_prob, chunk_v))\n",
    "    return context.view(bsz, num_heads, seqlen, head_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1d14c88-eb17-4a21-90b1-00cb0e941778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers and reshaping for longformer \n",
    "\n",
    "query_states = query_layer(hidden_states)\n",
    "key_states = key_layer(hidden_states)\n",
    "value_states = value_layer(hidden_states)\n",
    "\n",
    "query_states = query_states.view(batch_size, seq_length, num_attention_heads, attention_head_size).transpose(1, 2)\n",
    "key_states = key_states.view(batch_size, seq_length, num_attention_heads, attention_head_size).transpose(1, 2)\n",
    "value_states = value_states.view(batch_size, seq_length, num_attention_heads, attention_head_size).transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b276179-5137-4cf4-afc5-8a74369ed330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE\n",
    "\n",
    "if position_embedding_type == \"rotary\":\n",
    "    rotary_embeddings = RotaryEmbedding(attention_head_size)\n",
    "    query_states, key_states = rotary_embeddings(query_states, key_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "722ea165-71c8-4d62-8ac9-64c37385f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 4096, 513])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention scores\n",
    "\n",
    "window_size = 256\n",
    "\n",
    "attention_scores = sliding_chunks_matmul_qk(query_states, key_states, window_size, padding_value=0)*(1/(seq_length**0.5))\n",
    "attention_scores.shape # torch.Size([batch_size, num_attention_heads, seq_length, w*2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c3ac88a-98f6-4568-8f18-3de22da73b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mask : \n",
    "\n",
    "attention_mask = None\n",
    "\n",
    "if attention_mask is not None:\n",
    "    attention_scores = attention_scores + attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e8b9812-23bb-4da8-918e-fe404dd7d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention normalization and context layer\n",
    "\n",
    "attention_probs = nn.functional.softmax(attention_scores, dim=-1, dtype=torch.float32)\n",
    "attention_probs = dropout_layer(attention_probs)\n",
    "\n",
    "context = sliding_chunks_matmul_pv(attention_probs, value_states, window_size)\n",
    "context_layer = context.transpose(1, 2).contiguous()\n",
    "output = context_layer.view(context_layer.size(0),context_layer.size(1),context_layer.size(2)*context_layer.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b0004c3-138c-429e-a699-8569ffd8abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096, 1280])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape # torch.Size([batch_size, seq_length, hidden_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484c0d6-aedf-4a05-8a42-8fc8480b509d",
   "metadata": {},
   "source": [
    "Sparse Attention (ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "feb5ee27-0490-457f-ae67-bc1566885135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "170\n",
      "527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input : hidden states + sequence information (proteins + interactions map)\n",
    "\n",
    "# Random proteins information : \n",
    "def generate_list(n, Amin, Amax):\n",
    "    ni_list = []\n",
    "    remaining = n\n",
    "    while remaining > Amin:\n",
    "        ni = random.randint(Amin, min(Amax, remaining))\n",
    "        ni_list.append(ni)\n",
    "        remaining -= ni\n",
    "    ni_list.append(remaining)\n",
    "    return ni_list\n",
    "\n",
    "# Random proteins interactions : \n",
    "def generate_couples(n_couples, n_len):\n",
    "    couples = []\n",
    "    while len(couples) < n_couples :\n",
    "        i = random.randint(0, n_len - 1)\n",
    "        j = random.randint(0, n_len - 1)\n",
    "        if abs(i - j) > 1 and (i, j) not in couples and (j, i) not in couples:\n",
    "            couples.append((i, j))\n",
    "    return couples\n",
    "\n",
    "proteins_list = generate_list(seq_length, Amin = 50, Amax = 200) \n",
    "proteins_cs =  [0]+list(np.cumsum(np.array(proteins_list)))\n",
    "n = len(proteins_list)\n",
    "print(n)\n",
    "proteins_interactions = generate_couples(n_couples = 5 * n, n_len = n) # Max number of couples : n * (n - 3) / 2\n",
    "print(len(proteins_interactions)), print(int(n * (n - 3) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e84f4cb3-8756-4ed0-b336-7fd848540e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_block_positions(protein_starts, protein_pairs):\n",
    "    block_positions = []\n",
    "\n",
    "    for i, j in protein_pairs:\n",
    "        start_i = protein_starts[i]\n",
    "        start_j = protein_starts[j]\n",
    "        block_positions.append((start_i, start_j))\n",
    "\n",
    "    return block_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b27b35f-26ad-41c3-976b-df5525d0e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_crows(rows, n): \n",
    "    rows = np.array(rows)\n",
    "    counts = np.bincount(rows, minlength=n+1)\n",
    "    \n",
    "    # Si le tableau résultant est plus court que n+1, on ajoute des zéros à la fin\n",
    "    if counts.size < n+1:\n",
    "        counts = np.pad(counts, (0, n+1-counts.size), constant_values=0)\n",
    "    counts_cs = np.cumsum(counts)\n",
    "    return counts_cs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "578039b0-ebf8-4cbe-809c-9fc2eb35d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_coo_with_variable_blocks(attentions, block_positions, max_rows, max_cols):\n",
    "    # Listes pour stocker les données du tensor COO\n",
    "    indices_i = []\n",
    "    indices_j = []\n",
    "    values = []\n",
    "    \n",
    "    # Parcourir chaque bloc et ses indices positionnels\n",
    "    for (block, (block_i, block_j)) in zip(attentions, block_positions):\n",
    "        # Aplatir le bloc\n",
    "        flat_block = block.flatten()\n",
    "        num_rows, num_cols = block.shape\n",
    "        for idx, val in enumerate(flat_block):\n",
    "            row_idx = idx // num_cols\n",
    "            col_idx = idx % num_cols\n",
    "            \n",
    "            global_row_idx = block_i + row_idx\n",
    "            global_col_idx = block_j + col_idx\n",
    "            \n",
    "            if global_row_idx < max_rows and global_col_idx < max_cols:\n",
    "                indices_i.append(global_row_idx)\n",
    "                indices_j.append(global_col_idx)\n",
    "                values.append(val)\n",
    "    \n",
    "    indices = torch.LongTensor([indices_i, indices_j])\n",
    "    values = torch.FloatTensor(values)\n",
    "    size = (max_rows, max_cols)\n",
    "    \n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n",
    "    \n",
    "    return sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a5212423-62df-4374-a433-5a752790c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_attention_matrix(query, key, proteins_interactions, proteins_cs, proteins_list):\n",
    "    batch_size, num_heads, seq_len, all_head_size = query.shape\n",
    "    start_time = time.time()\n",
    "    attentions = []\n",
    "    block_positions = []\n",
    "    block_sizes = []\n",
    "    sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "    max2 = 0\n",
    "    max3 = 0\n",
    "    tfor = time.time()\n",
    "    spm = []\n",
    "    for i, j in sorted_proteins_interactions :\n",
    "        \n",
    "        # Blocks\n",
    "        query_block = query[:, :, proteins_cs[i]:proteins_cs[i+1], :]\n",
    "        key_block = key[:, :, proteins_cs[j]:proteins_cs[j+1], :]\n",
    "        \n",
    "        # Compute attention matrix for the 2 blocks\n",
    "        attention_block = torch.matmul(query_block, key_block.transpose(-1, -2)).squeeze()\n",
    "        attentions.append(attention_block) \n",
    "\n",
    "        max2 = max(max2, attention_block.shape[-2])\n",
    "        max3 = max(max3, attention_block.shape[-1])\n",
    "\n",
    "        block_positions.append((proteins_cs[i], proteins_cs[j]))\n",
    "        block_sizes.append((proteins_list[i], proteins_list[j]))\n",
    "\n",
    "    print(f'Time for attention matrix computation : {time.time()-start_time}')\n",
    "    \n",
    "    # Padding for bsr storage :\n",
    "    padded_attentions = []\n",
    "    for attention_block in attentions:\n",
    "        s = attention_block.shape\n",
    "        padded_attention_block = F.pad(attention_block, (0, max3 - s[-1], 0, max2 - s[-2]), \"constant\", 0)\n",
    "        padded_attentions.append(padded_attention_block)\n",
    "        \n",
    "    # Create block sparse matrix with torch.sparse_bsr_tensor\n",
    "    # columns and rows : \n",
    "    t2 = time.time()\n",
    "    col_indices = [x[1] for x in sorted_proteins_interactions]\n",
    "    rows = [x[0] for x in sorted_proteins_interactions]\n",
    "    n = len(proteins_cs) - 1\n",
    "    crow_indices = [0] + rows_to_crows(rows, n)[:-1]\n",
    "    crow_tensor = torch.stack([torch.tensor(crow_indices)] * 20)\n",
    "    col_tensor = torch.stack([torch.tensor(col_indices)] * 20)\n",
    "    # values :    \n",
    "    concatenated_attentions = torch.stack(padded_attentions, dim=1)\n",
    "    print(concatenated_attentions.shape)\n",
    "    #sparse_matrix = create_sparse_coo_with_variable_blocks(attentions, block_positions, seq_len, seq_len)\n",
    "    sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [20, 6800, 6800])\n",
    "    print(f'Time for sparse matrix creation : {time.time() - t2}')\n",
    "    \n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d6ecd0b8-57cb-49ff-8b61-e0cbe9d37d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for attention matrix computation : 0.20403671264648438\n",
      "torch.Size([20, 170, 200, 200])\n",
      "Time for sparse matrix creation : 0.18862628936767578\n",
      "torch.Size([20, 6800, 6800])\n"
     ]
    }
   ],
   "source": [
    "attentions_scores_sparse = sparse_attention_matrix(query, key, proteins_interactions, proteins_cs, proteins_list)\n",
    "print(attentions_scores_sparse.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3315a92f-0c87-4394-af82-d0062aec8210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 6800, 6800])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_scores = attentions_scores_sparse.to_dense()\n",
    "dense_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "54242aae-51b6-4da6-a19a-e9793d3f62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements: 924800000\n",
      "Non-zero elements: 136000000\n",
      "Zero count: 788800000\n",
      "Percentage of zero elements: 85.29%\n"
     ]
    }
   ],
   "source": [
    "total_elements = torch.prod(torch.tensor(attentions_scores_sparse.shape)).item()  # Nombre total d'éléments dans le tensor dense\n",
    "non_zero_count = attentions_scores_sparse._nnz()*max(proteins_list)*max(proteins_list)*20  # Nombre d'éléments non nuls stockés dans le sparse tensor\n",
    "zero_count = total_elements - non_zero_count  # Nombre d'éléments nuls\n",
    "zero_percentage = (zero_count / total_elements) * 100  # Pourcentage de zéros\n",
    "\n",
    "print(f\"Total elements: {total_elements}\")\n",
    "print(f\"Non-zero elements: {non_zero_count}\")\n",
    "print(f\"Zero count: {zero_count}\")\n",
    "print(f\"Percentage of zero elements: {zero_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "73fcec1b-f0a4-464d-9844-7129e4d320f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_values' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_values' is only available for these backends: [MPS, Meta, SparseCPU, SparseMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:75 [backend fallback]\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1387 [kernel]\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\nBackendSelect: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterFunctionalization_3.cpp:24643 [kernel]\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5216 [kernel]\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14672 [kernel]\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dense_size \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(dense_scores\u001b[38;5;241m.\u001b[39mstorage())\n\u001b[0;32m----> 4\u001b[0m sparse_size \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(\u001b[43mattentions_scores_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstorage()) \u001b[38;5;241m+\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(attentions_scores_sparse\u001b[38;5;241m.\u001b[39m_indices()\u001b[38;5;241m.\u001b[39mstorage())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDense tensor size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdense_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse tensor size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_values' with arguments from the 'SparseCsrCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_values' is only available for these backends: [MPS, Meta, SparseCPU, SparseMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:75 [backend fallback]\nMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1387 [kernel]\nSparseMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\nBackendSelect: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/RegisterFunctionalization_3.cpp:24643 [kernel]\nNamed: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5216 [kernel]\nAutogradOther: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradCPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradCUDA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradHIP: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradXLA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMPS: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradIPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradXPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradHPU: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradVE: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradLazy: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMTIA: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse1: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse2: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradPrivateUse3: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradMeta: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nAutogradNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:18740 [autograd kernel]\nTracer: registered at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14672 [kernel]\nAutocastCPU: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "dense_size = sys.getsizeof(dense_scores.storage())\n",
    "sparse_size = sys.getsizeof(attentions_scores_sparse._values().storage()) + sys.getsizeof(attentions_scores_sparse._indices().storage())\n",
    "\n",
    "print(f\"Dense tensor size: {dense_size} bytes\")\n",
    "print(f\"Sparse tensor size: {sparse_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593b67e-db1d-425e-bcbe-c7edfc1f1445",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78b816-108c-4b99-9faf-316c38f12df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d9162464-3c91-4a0e-8e94-5dcd8e483dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([0, 3, 5, 7, 8]),\n",
       "       col_indices=tensor([0, 1, 2, 0, 4, 5, 6, 7]),\n",
       "       values=tensor([[[1, 2],\n",
       "                       [3, 4]],\n",
       "\n",
       "                      [[5, 6],\n",
       "                       [7, 8]],\n",
       "\n",
       "                      [[1, 2],\n",
       "                       [3, 4]],\n",
       "\n",
       "                      [[5, 6],\n",
       "                       [7, 8]],\n",
       "\n",
       "                      [[1, 2],\n",
       "                       [3, 4]],\n",
       "\n",
       "                      [[5, 6],\n",
       "                       [7, 8]],\n",
       "\n",
       "                      [[1, 2],\n",
       "                       [3, 4]],\n",
       "\n",
       "                      [[5, 6],\n",
       "                       [7, 8]]]), size=(8, 16), nnz=8, layout=torch.sparse_bsr)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crow_indices = [0, 3, 5, 7, 8]\n",
    "col_indices = [0, 1, 2, 0, 4, 5 , 6, 7]\n",
    "values = [[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[1, 2], [3, 4]], [[5, 6], [7, 8]], [[1, 2], [3, 4]], [[5, 6], [7, 8]],[[1, 2], [3, 4]],[[5, 6], [7, 8]]]\n",
    "bsr = torch.sparse_bsr_tensor(torch.tensor(crow_indices, dtype=torch.int64),torch.tensor(col_indices, dtype=torch.int64),torch.tensor(values), dtype=torch.int64)\n",
    "bsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f5cf8297-8a0f-4551-a7c6-ca99e1f3edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [3, 4, 7, 8, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [5, 6, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "        [7, 8, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 1, 2, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 3, 4, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsr.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6eed454b-665f-4c6f-b9be-f439930be8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(values[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "305ea77b-3cc1-4be0-82bf-98f426b0bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0],\n",
      "        [0, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Supposons que vous ayez des valeurs avec des indices inégaux\n",
    "indices = torch.tensor([[0, 1, 2, 2], [0, 1, 0, 1]])  # Les indices de chaque élément non-nul\n",
    "values = torch.tensor([1, 2, 3, 4])  # Les valeurs correspondantes\n",
    "size = (3, 2)  # La taille totale de la matrice\n",
    "\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n",
    "print(sparse_tensor.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ae166ba3-7828-466d-9dbf-027c899d8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_sparse_coo_with_variable_blocks(attentions, block_positions, max_rows, max_cols):\n",
    "    # Listes pour stocker les données du tensor COO\n",
    "    indices_i = []\n",
    "    indices_j = []\n",
    "    values = []\n",
    "    \n",
    "    # Parcourir chaque bloc et ses indices positionnels\n",
    "    for (block, (block_i, block_j)) in zip(attentions, block_positions):\n",
    "        # Aplatir le bloc\n",
    "        flat_block = block.flatten()\n",
    "        \n",
    "        # Obtenir les indices relatifs à l'intérieur du bloc\n",
    "        num_rows, num_cols = block.shape\n",
    "        for idx, val in enumerate(flat_block):\n",
    "            # Calculer l'indice relatif dans le bloc\n",
    "            row_idx = idx // num_cols\n",
    "            col_idx = idx % num_cols\n",
    "            \n",
    "            # Calculer les indices globaux\n",
    "            global_row_idx = block_i + row_idx\n",
    "            global_col_idx = block_j + col_idx\n",
    "            \n",
    "            # Assurer que les indices sont dans les limites\n",
    "            if global_row_idx < max_rows and global_col_idx < max_cols:\n",
    "                indices_i.append(global_row_idx)\n",
    "                indices_j.append(global_col_idx)\n",
    "                values.append(val)\n",
    "    \n",
    "    indices = torch.LongTensor([indices_i, indices_j])\n",
    "    values = torch.FloatTensor(values)\n",
    "    size = (max_rows, max_cols)\n",
    "    \n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n",
    "    \n",
    "    return sparse_tensor\n",
    "\n",
    "# Exemple d'utilisation\n",
    "blocks = [torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5, 6]])]\n",
    "positions = [(0, 0), (2, 1)]\n",
    "max_rows, max_cols = 10000, 100000  # Taille globale de la matrice\n",
    "\n",
    "sparse_matrix = create_sparse_coo_with_variable_blocks(blocks, positions, max_rows, max_cols)\n",
    "dense_matrix = sparse_matrix.to_dense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "29480970-f91f-4d66-a13e-b3029961e96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense tensor size: 4000000048 bytes\n",
      "Sparse tensor size: 216 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "dense_size = sys.getsizeof(dense_matrix.storage())\n",
    "sparse_size = sys.getsizeof(sparse_matrix._values().storage()) + sys.getsizeof(sparse_matrix._indices().storage())\n",
    "\n",
    "print(f\"Dense tensor size: {dense_size} bytes\")\n",
    "print(f\"Sparse tensor size: {sparse_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae6b94-e5f7-4ef4-82da-246e95d4413a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877393e-117f-481a-947a-ed3208f121e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01718c-5a64-4e5a-95e4-1cb83805139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750885f2-b239-4a4c-9b59-d6786a5e7273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a2450-37f4-47af-bbef-ba5f8e6007d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
