{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fed56632-4ef9-4e84-ba5f-afa567899c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as F\n",
    "from typing import Union\n",
    "from functools import lru_cache\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e7adf38c-82ba-449e-8406-fd46c00f0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters : \n",
    "\n",
    "batch_size = 1\n",
    "seq_length = 4096\n",
    "num_attention_heads = 20\n",
    "hidden_size = 1280\n",
    "attention_head_size = int(hidden_size / num_attention_heads)\n",
    "all_head_size = num_attention_heads * attention_head_size\n",
    "\n",
    "position_embedding_type = \"rotary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a0593d1b-f665-4b09-b226-104885e3d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize layers : \n",
    "\n",
    "query_layer = nn.Linear(hidden_size, all_head_size)\n",
    "key_layer = nn.Linear(hidden_size, all_head_size)\n",
    "value_layer = nn.Linear(hidden_size, all_head_size)\n",
    "\n",
    "dropout_layer = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8bcfc9e1-ad1c-4978-b644-4d20970d3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement RoPE : \n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    cos = cos[:, :, : x.shape[-2], :]\n",
    "    sin = sin[:, :, : x.shape[-2], :]\n",
    "    return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "class RotaryEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary position embeddings based on those in\n",
    "    [RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer). Query and keys are transformed by rotation\n",
    "    matrices which depend on their relative positions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        # Generate and save the inverse frequency buffer (non trainable)\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
    "        inv_freq = inv_freq\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        self._seq_len_cached = None\n",
    "        self._cos_cached = None\n",
    "        self._sin_cached = None\n",
    "\n",
    "    def _update_cos_sin_tables(self, x, seq_dimension=2):\n",
    "        seq_len = x.shape[seq_dimension]\n",
    "\n",
    "        # Reset the tables if the sequence length has changed,\n",
    "        # or if we're on a new device (possibly due to tracing for instance)\n",
    "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
    "            self._seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq)\n",
    "            freqs = torch.outer(t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
    "\n",
    "            self._cos_cached = emb.cos()[None, None, :, :]\n",
    "            self._sin_cached = emb.sin()[None, None, :, :]\n",
    "\n",
    "        return self._cos_cached, self._sin_cached\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
    "\n",
    "        return (\n",
    "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
    "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9d0552b2-fdb1-4372-a2ce-a1c625d00b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose for attentions :\n",
    "\n",
    "def transpose_for_scores(x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "292b7e9d-691a-44a2-9c1e-af0cbdfbeeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096, 1280])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = torch.randn((1, seq_length, hidden_size))\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d9d79b95-8b70-4a2a-b849-40e8c453df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 1280])\n",
      "torch.Size([1, 20, 4096, 64])\n"
     ]
    }
   ],
   "source": [
    "# Query :\n",
    "\n",
    "mixed_query_layer = query_layer(hidden_states)\n",
    "print(mixed_query_layer.shape)\n",
    "query = transpose_for_scores(mixed_query_layer)\n",
    "query = query * attention_head_size**-0.5\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2c0ad8ea-3922-46a3-b1c7-7710bcf82f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key, Value :\n",
    "\n",
    "key = key_layer(hidden_states)\n",
    "key = transpose_for_scores(key)\n",
    "\n",
    "value = value_layer(hidden_states)\n",
    "value = transpose_for_scores(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d22f7e70-9994-4591-b124-0f9ed3a0dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding : \n",
    "\n",
    "if position_embedding_type == \"rotary\":\n",
    "    rotary_embeddings = RotaryEmbedding(attention_head_size)\n",
    "    query, key = rotary_embeddings(query, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6f138f50-402b-4b94-a509-69e460f66d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for full matmul : 0.8946590423583984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 4096, 4096])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication for attention scores :\n",
    "#tmean = []\n",
    "#for _ in range(0, 1) : \n",
    "start_time = time.time()\n",
    "attention_scores_full = torch.matmul(query, key.transpose(-1, -2))\n",
    "print(f'Elapsed time for full matmul : {time.time()-start_time}')\n",
    "#tmean.append(time.time()-start_time)\n",
    "attention_scores_full.shape\n",
    "\n",
    "#print(sum(tmean)/len(tmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5e46d2ce-64c2-4886-8e7d-bc39a7040917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mask : \n",
    "\n",
    "attention_mask_full = None\n",
    "if attention_mask_full is not None:\n",
    "    # Apply the attention mask is (precomputed for all layers in EsmModel forward() function)\n",
    "    attention_mask_full = attention_mask_full\n",
    "    attention_scores_full = attention_scores_full + attention_mask_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "473890b2-c3a1-4b27-b353-8a4edc51fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations before Att*V : \n",
    "\n",
    "attention_probs_full = nn.functional.softmax(attention_scores_full, dim=-1)\n",
    "attention_probs_full = dropout_layer(attention_probs_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bb0d7bdb-571a-4e73-9ad4-960a3edcb256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for context layer matmul : 1.059563159942627\n",
      "torch.Size([1, 4096, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Context layer :\n",
    "t=time.time()\n",
    "context = torch.matmul(attention_probs_full, value)\n",
    "print(f'Elapsed time for context layer matmul : {time.time()-t}')\n",
    "context_layer = context.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "new_context_layer_shape = context_layer.size()[:-2] + (all_head_size,)\n",
    "context_layer = context_layer.view(new_context_layer_shape)\n",
    "print(context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e02ae2c5-fdac-402b-972f-f2eeed5fdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "output_attentions = True\n",
    "outputs = (context_layer, attention_probs_full) if output_attentions else (context_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "02007968-0b02-4d92-8659-228e8ed68b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096, 1280]), torch.Size([1, 20, 4096, 4096]))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62697fd6-640a-47c8-ae36-018ef6eb5e79",
   "metadata": {},
   "source": [
    "Proteins blocks attentions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d1cbf920-5056-4343-bbdc-03c7e3bbd54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 197, 445, 623, 825, 1075, 1243, 1403, 1509, 1605, 1729, 1917, 2147, 2241, 2321, 2566, 2636, 2841, 3049, 3158, 3246, 3392, 3514, 3638, 3723, 3821, 4077, 4096]\n",
      "27\n",
      "135\n",
      "324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input : hidden states + sequence information (proteins + interactions map)\n",
    "\n",
    "# Random proteins information : \n",
    "def generate_list(n, Amin, Amax):\n",
    "    ni_list = []\n",
    "    remaining = n\n",
    "    while remaining > Amin:\n",
    "        ni = random.randint(Amin, min(Amax, remaining))\n",
    "        ni_list.append(ni)\n",
    "        remaining -= ni\n",
    "    ni_list.append(remaining)\n",
    "    return ni_list\n",
    "\n",
    "# Random proteins interactions : \n",
    "def generate_couples(n_couples, n_len):\n",
    "    couples = []\n",
    "    while len(couples) < n_couples :\n",
    "        i = random.randint(0, n_len - 1)\n",
    "        j = random.randint(0, n_len - 1)\n",
    "        if abs(i - j) > 1 and (i, j) not in couples and (j, i) not in couples:\n",
    "            couples.append((i, j))\n",
    "    return couples\n",
    "\n",
    "proteins_sizes = generate_list(seq_length, Amin = 65, Amax = 260) \n",
    "proteins_cs =  [0]+list(np.cumsum(np.array(proteins_sizes)))\n",
    "print(proteins_cs)\n",
    "n = len(proteins_sizes)\n",
    "print(n)\n",
    "proteins_interactions = generate_couples(n_couples = 5 * n, n_len = n) # Max number of couples : n * (n - 3) / 2\n",
    "sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "print(len(proteins_interactions)), print(int(n * (n - 3) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b12cb068-0960-4776-ad05-88bdc619fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor_padding(tensor, proteins_sizes, block_size):\n",
    "    _, seq_len, hidden_dim = tensor.shape\n",
    "    sub_blocks = []\n",
    "    start_index = 0\n",
    "    padding_storage = []\n",
    "\n",
    "    for i, size in enumerate(proteins_sizes):\n",
    "        num_full_blocks = size // block_size  # Nombre de sous-blocs entiers\n",
    "        end_index = start_index + num_full_blocks * block_size  # Index de fin pour les sous-blocs entiers\n",
    "        if num_full_blocks > 0:\n",
    "            for block in range(num_full_blocks) : \n",
    "                sub_blocks.append(tensor[0][start_index + block * block_size : start_index + (block+1) * block_size].reshape(block_size, hidden_dim).unsqueeze(0))\n",
    "        \n",
    "        remainder = size % block_size\n",
    "        padding_storage.append((i, num_full_blocks, remainder))\n",
    "        \n",
    "        if remainder > 0:\n",
    "            padding = torch.zeros((block_size - remainder, hidden_dim), dtype=tensor.dtype, device=tensor.device)\n",
    "            remainder_block = torch.cat([tensor[0][end_index:end_index + remainder], padding], dim=0)\n",
    "            sub_blocks.append(remainder_block.unsqueeze(0))\n",
    "        \n",
    "        start_index += size\n",
    "    if sub_blocks:\n",
    "        result_tensor = torch.cat(sub_blocks, dim=0)\n",
    "            \n",
    "    return result_tensor.unsqueeze(0), padding_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5375b85a-db9d-4211-9411-2e466c3e7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_proteins_padding(sorted_proteins_interactions, proteins_lengths, block_size):\n",
    "    num_blocks = [(length + block_size - 1) // block_size for length in proteins_lengths]  # (length + block_size - 1) // block_size arrondit à l'entier supérieur\n",
    "\n",
    "    num_blocks_cs = np.cumsum([0] + num_blocks).tolist()\n",
    "    index = 0\n",
    "    chunked_blocks = []\n",
    "    \n",
    "    for h in num_blocks:\n",
    "        for j in range(h):\n",
    "            chunked_blocks.append(index)\n",
    "            index += 1\n",
    "\n",
    "    block_interactions = []\n",
    "    \n",
    "    for i, j in sorted_proteins_interactions:\n",
    "        for k in range(num_blocks[i]):\n",
    "            for h in range(num_blocks[j]):\n",
    "                block_interactions.append((num_blocks_cs[i] + k, num_blocks_cs[j] + h))\n",
    "\n",
    "    return block_interactions, chunked_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "da696bde-e738-4ed0-94ff-df9df377eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_for_scores_padding(x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        x_permuted = x.permute(0, 3, 2, 1, 4)\n",
    "        return x_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "478c90d6-8638-484e-bfab-d1ba99618020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_attention_matrix_padding(query, key, proteins_interactions, proteins_cs, proteins_list, block_size):\n",
    "    batch_size, num_heads, bloc_size_exp, num_blocks, all_head_size = query.shape\n",
    "    assert bloc_size_exp == block_size\n",
    "    start_time = time.time()\n",
    "    attentions = []\n",
    "    block_positions = []\n",
    "    sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "    \n",
    "    for i, j in sorted_proteins_interactions :\n",
    "        # Blocks\n",
    "        query_block = query[:, :, :,i:i+1, :]\n",
    "        key_block = key[:, :, :,j:j+1, :]\n",
    "        \n",
    "        # Compute attention matrix for the 2 blocks\n",
    "        attention_block = torch.matmul(query_block, key_block.transpose(-1, -2)).squeeze()\n",
    "        attentions.append(attention_block) \n",
    "\n",
    "    amc = time.time()-start_time\n",
    "\n",
    "    # Create block sparse matrix with torch.sparse_bsr_tensor\n",
    "    \n",
    "    # columns and rows : \n",
    "    t2 = time.time()\n",
    "    \n",
    "    col_indices = [x[1] for x in sorted_proteins_interactions]\n",
    "    rows = [x[0] for x in sorted_proteins_interactions]\n",
    "    crow_indices = [0] + rows_to_crows(rows, len(proteins_cs) - 1)[:-1] # CHECK CROW\n",
    "    crow_tensor = torch.stack([torch.tensor(crow_indices)] * 20)\n",
    "    col_tensor = torch.stack([torch.tensor(col_indices)] * 20)\n",
    "\n",
    "    # values :    \n",
    "    concatenated_attentions = torch.stack(attentions, dim=1)\n",
    "\n",
    "    #sparse_matrix = create_sparse_coo_with_variable_blocks(attentions, block_positions, seq_len, seq_len)\n",
    "    sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [num_heads, num_blocks*block_size, num_blocks*block_size])\n",
    "    smc = time.time() - t2\n",
    "    \n",
    "    return sparse_matrix, amc, smc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "f9e80eb8-49e3-4790-9e85-0a07937ece3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 1280])\n",
      "[(0, 3, 5), (1, 3, 56), (2, 2, 50), (3, 3, 10), (4, 3, 58), (5, 2, 40), (6, 2, 32), (7, 1, 42), (8, 1, 32), (9, 1, 60), (10, 2, 60), (11, 3, 38), (12, 1, 30), (13, 1, 16), (14, 3, 53), (15, 1, 6), (16, 3, 13), (17, 3, 16), (18, 1, 45), (19, 1, 24), (20, 2, 18), (21, 1, 58), (22, 1, 60), (23, 1, 21), (24, 1, 34), (25, 4, 0), (26, 0, 19)]\n",
      "torch.Size([1, 76, 64, 1280])\n",
      "torch.Size([1, 20, 64, 76, 64])\n",
      "torch.Size([20, 4864, 64])\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "block_size = 64\n",
    "\n",
    "chunked_hidden_states_padding, padding_storage = reshape_tensor_padding(hidden_states, proteins_sizes, block_size)\n",
    "print(hidden_states.shape)\n",
    "print(padding_storage)\n",
    "print(chunked_hidden_states_padding.shape)\n",
    "chunked_mixed_query_layer_padding = query_layer(chunked_hidden_states_padding)\n",
    "chunked_query_padding = transpose_for_scores_padding(chunked_mixed_query_layer_padding)\n",
    "chunked_query_padding = chunked_query_padding * attention_head_size**-0.5\n",
    "print(chunked_query_padding.shape)\n",
    "\n",
    "chunked_key_padding = key_layer(chunked_hidden_states_padding)\n",
    "chunked_key_padding = transpose_for_scores_padding(chunked_key_padding)\n",
    "\n",
    "chunked_value_padding = value_layer(chunked_hidden_states_padding)\n",
    "chunked_value_padding = transpose_for_scores_padding(chunked_value_padding)\n",
    "chunked_value_padding = chunked_value_padding.reshape(1, num_attention_heads , -1, attention_head_size).squeeze()\n",
    "\n",
    "print(chunked_value_padding.shape)\n",
    "print(len(padding_storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0775c804-abbc-4079-98db-35eaee4ab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_interactions_padding, chunked_blocks_padding = chunk_proteins_padding(sorted_proteins_interactions, proteins_sizes, block_size)\n",
    "proteins_chunked_sizes_padding = [block_size for _ in chunked_blocks_padding]\n",
    "proteins_chunked_cs_padding =  [0]+list(np.cumsum(np.array(proteins_chunked_sizes_padding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "9dbb920f-fb9b-495c-9bfb-45a11b0c1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time : 1.1163229942321777\n"
     ]
    }
   ],
   "source": [
    "tt = time.time()\n",
    "spmd, amc, smc = sparse_attention_matrix_padding(chunked_query_padding, chunked_key_padding, chunked_interactions_padding, proteins_chunked_cs_padding, proteins_chunked_sizes_padding, block_size)\n",
    "print(f'Elapsed time : {time.time()-tt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e32848ae-51ae-49f1-83d1-6e0bbc0dbef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0970592498779297, 0.005131959915161133)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amc, smc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6dfd472a-6422-4b91-8073-038dfba05212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 4864, 4864])\n"
     ]
    }
   ],
   "source": [
    "from torch.sparse._triton_ops import bsr_softmax, bsr_dense_mm # Only supported by CUDA and Triton ? \n",
    "\n",
    "# chunked_sparse_probs = bsr_softmax(chunked_sparse_matrix, dim=-1)\n",
    "chunked_sparse_probs_pd = sparse_bsr_dropout(spmd, 0.1, True)\n",
    "print(chunked_sparse_probs_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "bf338d9d-a78d-471a-9c60-fc5643ffb5be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[402], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_context \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chunked_value_padding\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     chunked_context \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_triton_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbsr_dense_mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunked_sparse_probs_pd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_value_padding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     batch_context\u001b[38;5;241m.\u001b[39mappend(chunked_context)\n\u001b[1;32m      7\u001b[0m chunked_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batch_context, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "tv = time.time()\n",
    "batch_context = []\n",
    "for batch in range(chunked_value_padding.shape[0]):\n",
    "    chunked_context = torch.sparse._triton_ops.bsr_dense_mm(chunked_sparse_probs_pd[batch], chunked_value_padding[batch])\n",
    "    batch_context.append(chunked_context)\n",
    "    \n",
    "chunked_context = torch.stack(batch_context, dim=0).unsqueeze(0)\n",
    "print(f'Elapsed time for context layer matmul : {time.time()-tv}')\n",
    "# Only way to perform batched matmul between sparse tensor and dense tensor (bmm sparse not implemented yet) - max : dim = 2 * dim = 2\n",
    "\n",
    "print(chunked_context.shape)\n",
    "\n",
    "chunked_context_layer = chunked_context.permute(0, 2, 1, 3).contiguous()\n",
    "new_chunked_context_layer_shape = chunked_context_layer.size()[:-2] + (all_head_size,)\n",
    "chunked_context_layer = chunked_context_layer.view(new_chunked_context_layer_shape)\n",
    "print(chunked_context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee3175-4edf-4251-a065-5251d264c4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c08ad-2981-4355-81dc-0cf14d694128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822ed4f-84c3-477c-86d1-4ad36afb10ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d5051b0-4a0c-425f-ae62-71c93f081ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide k, q, v based on block_size : \n",
    "\n",
    "def reshape_tensor(tensor, proteins_sizes, block_size):\n",
    "    _, seq_len, hidden_dim = tensor.shape\n",
    "    sub_blocks = []\n",
    "    start_index = 0\n",
    "\n",
    "        for size in proteins_sizes:\n",
    "        num_full_blocks = size // block_size  # Nombre de sous-blocs entiers\n",
    "        end_index = start_index + num_full_blocks * block_size  # Index de fin pour les sous-blocs entiers\n",
    "        if num_full_blocks > 0:\n",
    "            sub_blocks.append(tensor[0][start_index:end_index].reshape(num_full_blocks * block_size, hidden_dim))\n",
    "        start_index += size\n",
    "\n",
    "    if sub_blocks:\n",
    "        result_tensor = torch.cat(sub_blocks, dim=0)\n",
    "    print(result_tensor.shape)\n",
    "    return result_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2aa25ea3-daad-4a6e-b27d-5c174be7552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide interactions in blocks : \n",
    "\n",
    "block_size = 50\n",
    "\n",
    "def chunk_proteins(sorted_proteins_interactions, proteins_lengths, block_size):\n",
    "    # Calculer le nombre complet de blocs pour chaque protéine\n",
    "    num_blocks = [length // block_size for length in proteins_lengths]\n",
    "\n",
    "    # Cumulative sum pour obtenir les indices de début pour chaque protéine dans la grille globale\n",
    "    num_blocks_cs = np.cumsum([0] + num_blocks).tolist()\n",
    "    index = 0\n",
    "    chunked_blocks = []\n",
    "    \n",
    "    for h in num_blocks : \n",
    "        for j in range(h) : \n",
    "            chunked_blocks.append(index)\n",
    "            index +=1\n",
    "    block_interactions = []\n",
    "              \n",
    "    for i, j in sorted_proteins_interactions:\n",
    "        for k in range(num_blocks[i]):\n",
    "            num_blocks_cs[i] + k\n",
    "            for h in range(num_blocks[j]):\n",
    "                block_interactions.append((num_blocks_cs[i] + k, num_blocks_cs[j] + h))\n",
    "\n",
    "    return block_interactions, chunked_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d35343de-8c7c-4828-b70f-465d40ca48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_crows(rows, n): \n",
    "    rows = np.array(rows)\n",
    "    counts = np.bincount(rows, minlength=n+1)\n",
    "    \n",
    "    if counts.size < n+1:\n",
    "        counts = np.pad(counts, (0, n+1-counts.size), constant_values=0)\n",
    "    counts_cs = np.cumsum(counts)\n",
    "    \n",
    "    return counts_cs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "748b424b-13e7-4e0e-8bed-f8fd35ab67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_attention_matrix(query, key, proteins_interactions, proteins_cs, proteins_list, block_size):\n",
    "    batch_size, num_heads, seq_len, all_head_size = query.shape\n",
    "    start_time = time.time()\n",
    "    attentions = []\n",
    "    block_positions = []\n",
    "    sorted_proteins_interactions = sorted(proteins_interactions, key=lambda x: x[0])\n",
    "    \n",
    "    for i, j in sorted_proteins_interactions :\n",
    "        # Blocks\n",
    "        query_block = query[:, :, proteins_cs[i]:proteins_cs[i+1], :]\n",
    "        key_block = key[:, :, proteins_cs[j]:proteins_cs[j+1], :]\n",
    "        \n",
    "        # Compute attention matrix for the 2 blocks\n",
    "        attention_block = torch.matmul(query_block, key_block.transpose(-1, -2)).squeeze()\n",
    "        attentions.append(attention_block) \n",
    "\n",
    "    amc = time.time()-start_time\n",
    "\n",
    "    # Create block sparse matrix with torch.sparse_bsr_tensor\n",
    "    \n",
    "    # columns and rows : \n",
    "    t2 = time.time()\n",
    "    col_indices = [x[1] for x in sorted_proteins_interactions]\n",
    "    rows = [x[0] for x in sorted_proteins_interactions]\n",
    "    crow_indices = [0] + rows_to_crows(rows, len(proteins_cs) - 1)[:-1]\n",
    "    crow_tensor = torch.stack([torch.tensor(crow_indices)] * 20)\n",
    "    col_tensor = torch.stack([torch.tensor(col_indices)] * 20)\n",
    "\n",
    "    # values :    \n",
    "    concatenated_attentions = torch.stack(attentions, dim=1)\n",
    "\n",
    "    #sparse_matrix = create_sparse_coo_with_variable_blocks(attentions, block_positions, seq_len, seq_len)\n",
    "    sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [num_heads, len(proteins_list)*block_size, len(proteins_list)*block_size])\n",
    "    smc = time.time() - t2\n",
    "    \n",
    "    return sparse_matrix, amc, smc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0850593-79fc-4137-85d1-fc3c5233edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 50, 1280])\n",
      "torch.Size([20, 50, 48, 64])\n"
     ]
    }
   ],
   "source": [
    "# Query, Key, Value chunked by block_size\n",
    "block_size = 50\n",
    "\n",
    "chunked_hidden_states = reshape_tensor(hidden_states, proteins_sizes, block_size)\n",
    "print(chunked_hidden_states.shape)\n",
    "chunked_mixed_query_layer = query_layer(chunked_hidden_states)\n",
    "chunked_query = transpose_for_scores_padding(chunked_mixed_query_layer)\n",
    "chunked_query = chunked_query * attention_head_size**-0.5\n",
    "\n",
    "chunked_key = key_layer(chunked_hidden_states)\n",
    "chunked_key = transpose_for_scores_padding(chunked_key)\n",
    "\n",
    "chunked_value = value_layer(chunked_hidden_states)\n",
    "chunked_value = transpose_for_scores_padding(chunked_value).squeeze()\n",
    "print(chunked_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f948d8b3-f115-4e50-b54d-b7626a8b9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_interactions, chunked_blocks = chunk_proteins(sorted_proteins_interactions, proteins_sizes, block_size)\n",
    "proteins_chunked_sizes = [block_size for _ in chunked_blocks]\n",
    "proteins_chunked_cs =  [0]+list(np.cumsum(np.array(proteins_chunked_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92d55b18-0b10-4109-9c86-f9e57f712484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/4km91tb53796gmtpqmv98nbr0000gn/T/ipykernel_33199/1048404363.py:33: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  sparse_matrix = torch.sparse_bsr_tensor(crow_tensor, col_tensor, concatenated_attentions, size = [num_heads, len(proteins_list)*block_size, len(proteins_list)*block_size])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1450, 1450])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_sparse_matrix, attention_time, matrix_time = sparse_attention_matrix(chunked_query, chunked_key, chunked_interactions, proteins_chunked_cs, proteins_chunked_sizes, block_size)\n",
    "chunked_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c7dfcd3-7f3b-49c9-a2ba-3641935bb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_bsr_dropout(x, p, training):\n",
    "    values = x.values()  \n",
    "    dropped_values = F.dropout(values, p=p, training=training)  \n",
    "    new_sparse_tensor = torch.sparse_bsr_tensor(x.crow_indices(), x.col_indices(), dropped_values, size=x.size())\n",
    "    return new_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e034677f-579c-4b2a-9bf8-16d86f4a594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.sparse._triton_ops import bsr_softmax # Only supported by CUDA and Triton ? \n",
    "\n",
    "# chunked_sparse_probs = bsr_softmax(chunked_sparse_matrix, dim=-1)\n",
    "chunked_sparse_probs = sparse_bsr_dropout(chunked_sparse_matrix, 0.1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f1adbd26-90b4-4c11-8147-3e984187ee6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix, got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[395], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_context \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chunked_value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     chunked_context \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunked_sparse_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     batch_context\u001b[38;5;241m.\u001b[39mappend(chunked_context)\n\u001b[1;32m      7\u001b[0m chunked_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batch_context, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat2 must be a matrix, got 3-D tensor"
     ]
    }
   ],
   "source": [
    "tv = time.time()\n",
    "batch_context = []\n",
    "for batch in range(chunked_value.shape[0]):\n",
    "    chunked_context = torch.sparse.mm(chunked_sparse_probs[batch], chunked_value[batch])\n",
    "    batch_context.append(chunked_context)\n",
    "    \n",
    "chunked_context = torch.stack(batch_context, dim=0).unsqueeze(0)\n",
    "print(f'Elapsed time for context layer matmul : {time.time()-tv}')\n",
    "# Only way to perform batched matmul between sparse tensor and dense tensor (bmm sparse not implemented yet) - max : dim = 2 * dim = 2\n",
    "\n",
    "print(chunked_context.shape)\n",
    "\n",
    "chunked_context_layer = chunked_context.permute(0, 2, 1, 3).contiguous()\n",
    "new_chunked_context_layer_shape = chunked_context_layer.size()[:-2] + (all_head_size,)\n",
    "chunked_context_layer = chunked_context_layer.view(new_chunked_context_layer_shape)\n",
    "print(chunked_context_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c464636-f8a3-452b-91dd-bedca0957446",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_sizes_eval = [i for i in range(2, 101, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f57f57-655e-4666-8ff5-eaf946ca95e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b332775-512b-465a-8ad4-d9498a41a21f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m proteins_chunked_sizes \u001b[38;5;241m=\u001b[39m [block_size \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m chunked_blocks]\n\u001b[1;32m     28\u001b[0m proteins_chunked_cs \u001b[38;5;241m=\u001b[39m  [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mcumsum(np\u001b[38;5;241m.\u001b[39marray(proteins_chunked_sizes)))\n\u001b[0;32m---> 30\u001b[0m chunked_sparse_matrix, attention_time, matrix_time \u001b[38;5;241m=\u001b[39m \u001b[43msparse_attention_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunked_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked_interactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproteins_chunked_cs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproteins_chunked_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m chunked_sparse_probs \u001b[38;5;241m=\u001b[39m sparse_bsr_dropout(chunked_sparse_matrix, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m batch_context \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m, in \u001b[0;36msparse_attention_matrix\u001b[0;34m(query, key, proteins_interactions, proteins_cs, proteins_list, block_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m     key_block \u001b[38;5;241m=\u001b[39m key[:, :, proteins_cs[j]:proteins_cs[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], :]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Compute attention matrix for the 2 blocks\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     attention_block \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     15\u001b[0m     attentions\u001b[38;5;241m.\u001b[39mappend(attention_block) \n\u001b[1;32m     17\u001b[0m amc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TO RUN TO EVALUATE BLOCK_SIZE (very slow for 2 - start higher ?)\n",
    "\n",
    "attention_times = []\n",
    "sparse_matrix_creation_times = []\n",
    "total_times = []\n",
    "zero_values = []\n",
    "for block_size in blocks_sizes_eval : \n",
    "    attention_times_mean = []\n",
    "    sparse_matrix_creation_times_mean = []\n",
    "    total_times_mean = []\n",
    "    zero_values_mean = []\n",
    "    for s in range(1, 5) : \n",
    "        tt = time.time()\n",
    "        chunked_hidden_states = reshape_tensor(hidden_states, proteins_sizes, block_size)\n",
    "        \n",
    "        chunked_mixed_query_layer = query_layer(chunked_hidden_states)\n",
    "        chunked_query = transpose_for_scores(chunked_mixed_query_layer)\n",
    "        chunked_query = chunked_query * attention_head_size**-0.5\n",
    "        \n",
    "        chunked_key = key_layer(chunked_hidden_states)\n",
    "        chunked_key = transpose_for_scores(chunked_key)\n",
    "        \n",
    "        chunked_value = value_layer(chunked_hidden_states)\n",
    "        chunked_value = transpose_for_scores(chunked_value).squeeze()\n",
    "    \n",
    "        chunked_interactions, chunked_blocks = chunk_proteins(sorted_proteins_interactions, proteins_sizes, block_size)\n",
    "        proteins_chunked_sizes = [block_size for _ in chunked_blocks]\n",
    "        proteins_chunked_cs =  [0]+list(np.cumsum(np.array(proteins_chunked_sizes)))\n",
    "    \n",
    "        chunked_sparse_matrix, attention_time, matrix_time = sparse_attention_matrix(chunked_query, chunked_key, chunked_interactions, proteins_chunked_cs, proteins_chunked_sizes, block_size)\n",
    "\n",
    "        \n",
    "        chunked_sparse_probs = sparse_bsr_dropout(chunked_sparse_matrix, 0.1, True)\n",
    "    \n",
    "        batch_context = []\n",
    "        for batch in range(chunked_value.shape[0]):\n",
    "            chunked_context = torch.sparse.mm(chunked_sparse_probs[batch], chunked_value[batch])\n",
    "            batch_context.append(chunked_context)\n",
    "            \n",
    "        chunked_context = torch.stack(batch_context, dim=0).unsqueeze(0)\n",
    "    \n",
    "        chunked_context_layer = chunked_context.permute(0, 2, 1, 3).contiguous()\n",
    "        new_chunked_context_layer_shape = chunked_context_layer.size()[:-2] + (all_head_size,)\n",
    "        chunked_context_layer = chunked_context_layer.view(new_chunked_context_layer_shape)\n",
    "    \n",
    "        output_attentions = True\n",
    "        outputs = (chunked_context_layer, chunked_sparse_probs) if output_attentions else (chunked_context_layer,)\n",
    "        ft = time.time()-tt\n",
    "        nv = seq_length - chunked_hidden_states.shape[1]\n",
    "\n",
    "        attention_times_mean.append(attention_time)\n",
    "        sparse_matrix_creation_times_mean.append(matrix_time)\n",
    "        total_times_mean.append(ft)\n",
    "        zero_values_mean.append(nv)\n",
    "        print(zero_values_mean)\n",
    "\n",
    "    zero_values.append(sum(zero_values_mean)/len(zero_values_mean))\n",
    "    attention_times.append(sum(attention_times_mean)/len(attention_times_mean))\n",
    "    sparse_matrix_creation_times.append(sum(sparse_matrix_creation_times_mean)/len(sparse_matrix_creation_times_mean))\n",
    "    total_times.append(sum(total_times_mean)/len(total_times_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2544cd4-458d-4989-b03f-d8e643a0e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('/home/thibaut/blocks_sizes_8192.pickle', 'wb') as fichier0:\n",
    "    pickle.dump(blocks_sizes_eval, fichier0)\n",
    "\n",
    "with open('/home/thibaut/attention_times_8192.pickle', 'wb') as fichier1:\n",
    "    pickle.dump(attention_times, fichier1)\n",
    "\n",
    "with open('/home/thibaut/matrix_times_8192.pickle', 'wb') as fichier2:\n",
    "    pickle.dump(sparse_matrix_creation_times, fichier2)\n",
    "\n",
    "with open('/home/thibaut/global_times_8192.pickle', 'wb') as fichier3:\n",
    "    pickle.dump(total_times, fichier3)\n",
    "\n",
    "with open('/home/thibaut/zero_values_8192.pickle', 'wb') as fichier4:\n",
    "    pickle.dump(zero_values, fichier4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acac22b-67e7-42f7-877d-ec789db71532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
