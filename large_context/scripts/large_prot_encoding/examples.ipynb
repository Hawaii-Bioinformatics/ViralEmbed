{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ebe2f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mahdi/miniconda3/envs/temp/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee6d27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from model import SparseForTokenClassification\n",
    "from typing import Tuple, List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196eff1",
   "metadata": {},
   "source": [
    "### Extracting Embedding for Both Protein Sequences and for Genome\n",
    "#####  Extracting protien for a single protein \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9d03e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5493a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usign a short 10 amino acid sequence as a proof of concept.\n",
    "\n",
    "data  = [('seq_1', 'MLKKLSVFLI')]\n",
    "\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c4639",
   "metadata": {},
   "source": [
    "##### Recreate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac6ead1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3C' # or '5B'\n",
    "checkpoint = torch.load(f'./models/{version}/config_and_model.pth', map_location='cpu', weights_only=False)\n",
    "# checkpoint = torch.load(f'/home/thibaut/mahdi/models/{version}/config_and_model.pth', map_location='cpu', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f926f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "config = checkpoint['config']\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "sparse_model = SparseForTokenClassification(config=config)\n",
    "sparse_model.load_state_dict(model_state_dict)\n",
    "sparse_model = sparse_model.to(device)\n",
    "sparse_model = sparse_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "505e8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sparse_model(input_ids=batch_tokens, \n",
    "                      output_attentions = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9bd5dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1280])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbace3",
   "metadata": {},
   "source": [
    "### We can extract the sequence embeddings using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ee0ef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1280])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits[0,1:-1:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "58fc870d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "308d375c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12]),\n",
       " torch.Size([1, 20, 12, 12])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[output.attentions[i].size() for i in range(len(output.attentions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46373c",
   "metadata": {},
   "source": [
    "# Thibaut \n",
    "\n",
    "Could you include the code here that combines all the attention heads and layers into a single 10x10 matrix? It should be in a single function. For now, we will provide equal weights to each matrix, but the function should be able to take a different weighting scheme for each layer. See scaffold below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "501ae5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_attention(attentions: Tuple[torch.Tensor, ...], weight_scheme: List[float]) -> torch.Tensor:\n",
    "    x,y,n1,n2 = len(attentions), attentions[0][0].shape[0], attentions[0][0].shape[1], attentions[0][0].shape[2]\n",
    "    assert len(weight_scheme) == x * y\n",
    "    \n",
    "    weighted_sum = torch.zeros_like(attentions[0][0][0])\n",
    "\n",
    "    stacked_attentions = torch.stack(attentions, dim=0)\n",
    "    weights = torch.tensor(weight_scheme, dtype=stacked_attentions.dtype, device=stacked_attentions.device)\n",
    "\n",
    "    flattened_attentions = stacked_attentions.view(x * y, n1, n2)\n",
    "    weighted_sum = torch.sum(flattened_attentions * weights[:, None, None], dim=0)\n",
    "    \n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87d49809",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layars = len(output.attentions)\n",
    "nb_heads = output.attentions[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56a29d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1]*(nb_layars * nb_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "285cb6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_scheme = [1]*(nb_layars * nb_heads)\n",
    "len(weight_scheme), weight_scheme[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "36f57889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000],\n",
       "        [16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000, 16.0000,\n",
       "         16.0000, 16.0000, 16.0000, 16.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_combined_attention(output.attentions, weight_scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157784ee",
   "metadata": {},
   "source": [
    "### Computing the Complete Genome Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b076df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('some_genome', 'MLKKLSVFLIMLSVFLILKKLSVFLIMLKKLSVIMMMKV')], [10, 7, 9, 13])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = [('seq_1', 'MLKKLSVFLI'), ('seq_2', 'MLSVFLI'), ('seq_3', 'LKKLSVFLI'), ('seq_4', 'MLKKLSVIMMMKV')]\n",
    "\n",
    "# concat all the sequences in data\n",
    "prots_concatenated = \"\".join([x[1] for x in data])\n",
    "prots_lengths = [len(x[1]) for x in data]\n",
    "genome = [(\"some_genome\", prots_concatenated)]\n",
    "genome , prots_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b6ce53a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48fafe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels, batch_strs, batch_tokens = batch_converter(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8b1a1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sparse_model(input_ids=batch_tokens, \n",
    "                      output_attentions = True, \n",
    "                      proteins_sizes = torch.tensor(prots_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "539877fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'attentions'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8117ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 41, 1280])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c1dbfcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "668a123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 41, 41])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['attentions'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f69422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prots_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85fdfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIBAUT: my understanding is that two_step_selection= True determines whether to return all pairwise scores  or  not.\n",
    "# Adding here, causes an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89cfc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sparse_model(input_ids=batch_tokens, \n",
    "                      output_attentions = True, \n",
    "                      proteins_sizes = torch.tensor(prots_lengths),  two_step_selection= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096206d",
   "metadata": {},
   "source": [
    "### Ranking the pairwise interactions\n",
    "\n",
    "1. I know that we need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bec958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 assembled fragments\n",
      "Number of sequences to process : 0\n",
      "10 cpus availables\n",
      "0 fragments processed\n"
     ]
    }
   ],
   "source": [
    "from pair_ranking_script import get_pairs_dataset\n",
    "# I am going to run the code below step by step we can use exactly what is needed\n",
    "# output = get_pairs_dataset(\"../data/LR699048.fa\", \"./data/LR699048.pt\", \"./data/LR699048.txt\", plot_fragment_heatmap = False)\n",
    "# # generates the folowing\n",
    "# all_pairs: attention between all pairs of proteins \n",
    "# all_nc_pairs:  attention between all pairs of non-consecutive proteins\n",
    "# global_length: total number of all pairwise comparisons ()\n",
    "# non_consecutive_length: total number of all non-consecutive pairwise comparisons\n",
    "# database_dic: same as all_pairs but in dictionary format where key is genome name\n",
    "# all_top_pairs_labeled: same as all_pairs but with protein labels instead of protein indexes. Uses the labels_file to get the labels\n",
    "# all_top_pairs_labeled_nc: same as all_nc_pairs but with protein labels instead of protein indexes. Uses the labels_file to get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5ffcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pair_ranking_script import load_fasta_as_tuples\n",
    "data_assembled = load_fasta_as_tuples(\"../data/LR699048.fa\")\n",
    "    global_length = []\n",
    "    non_consecutive_length = []\n",
    "    all_length_dict = []\n",
    "    j = 0\n",
    "    all_top_pairs = []\n",
    "    all_top_pairs_nc = []\n",
    "    all_top_pairs_labeled = []\n",
    "    all_top_pairs_labeled_nc = []\n",
    "    database_dic = {}\n",
    "    mlp = []\n",
    "    genomes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIBAUT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
