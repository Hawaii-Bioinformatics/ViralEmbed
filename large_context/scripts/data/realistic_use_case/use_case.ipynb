{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from model import SparseForTokenClassification\n",
    "from typing import Tuple, List\n",
    "from pair_ranking_script import load_fasta_as_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51986\n"
     ]
    }
   ],
   "source": [
    "data1 = load_fasta_as_tuples(\"NZ_ANAO01000007_products_concatenated_pros.fasta\")\n",
    "data2 = load_fasta_as_tuples(\"NZ_ANAO01000007_products_proteins.fasta\")\n",
    "print(len(data1[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51988])\n",
      "torch.Size([152, 1072])\n"
     ]
    }
   ],
   "source": [
    "batch_labels1, batch_strs1, batch_tokens1 = batch_converter(data1) # GENOME\n",
    "batch_labels2, batch_strs2, batch_tokens2 = batch_converter(data2) # PROTEINS\n",
    "print(batch_tokens1.shape)\n",
    "print(batch_tokens2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3C' # or '5B'\n",
    "#checkpoint = torch.load(f'./models/{version}/config_and_model.pth', map_location='cpu', weights_only=False)\n",
    "checkpoint = torch.load(f'/home/thibaut/mahdi/models/{version}/config_and_model.pth', map_location='cpu', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "config = checkpoint['config']\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "sparse_model = SparseForTokenClassification(config=config)\n",
    "sparse_model.load_state_dict(model_state_dict)\n",
    "sparse_model = sparse_model.to(device)\n",
    "sparse_model = sparse_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete genome embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_tokens1 = batch_tokens1.to(device)\n",
    "    output = sparse_model(input_ids=batch_tokens1, output_attentions = False)\n",
    "\n",
    "# 1m53s for 52k aa sequence     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 51988, 1280])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape # Genome embeddings\n",
    "# torch.Size([1, 51988, 1280])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-contextualised proteins embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_tokens2 = batch_tokens2.to(device)\n",
    "    output2 = sparse_model(input_ids=batch_tokens2, output_attentions = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([152, 1072, 1280])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.logits.shape # Padded protein embeddings\n",
    "# torch.Size([number_proteins, longest_protein+2, 1280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove padding from embeddings - returns a list of embeddings. \n",
    "def remove_padding_embeddings(data, output) : \n",
    "    out = output.logits\n",
    "    res = []\n",
    "    for i, prot in enumerate(data) : \n",
    "        size = len(prot[1])\n",
    "        ex = out[i][1:size+1]\n",
    "        res.append(ex)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = remove_padding_embeddings(data2, output2) # List of non-padded non-contextualised protein embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualised protein embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_sum(liste) : \n",
    "        r = 0\n",
    "        res = [0]\n",
    "        for l in liste : \n",
    "            r+=l\n",
    "            res.append(int(r))\n",
    "        return res\n",
    "\n",
    "def extract_embeddding(embeddings, data, index):\n",
    "    proteins_sizes = [len(prot[1]) for prot in data]\n",
    "    embeddings = embeddings[:,1:-1,:]\n",
    "    proteins_size_cs = cumulative_sum(proteins_sizes)\n",
    "    start, end = proteins_size_cs[index], proteins_size_cs[index+1]\n",
    "    subset = embeddings[:,start:end,:]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 306, 1280])\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "B = extract_embeddding(output.logits, data2, 2)  \n",
    "# output.logits is the embeddings of the genome \n",
    "# data2 is the data list ('prot_id', 'SEQ') for every protein in the genome\n",
    "# 2 is the index of the desired protein in the genome\n",
    "print(B.shape)\n",
    "print(len(data2[2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteins pairs ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014, 174, 306, 296, 299, 85, 240, 466, 388, 374, 492, 490, 65, 391, 236, 471, 291, 644, 200, 103, 609, 85, 145, 142, 66, 430, 463, 515, 573, 433, 461, 210, 157, 72, 420, 314, 270, 67, 383, 437, 390, 338, 283, 114, 350, 390, 113, 799, 215, 308, 311, 494, 131, 298, 330, 537, 152, 449, 339, 308, 322, 301, 593, 41, 140, 483, 416, 225, 463, 173, 326, 477, 185, 144, 125, 475, 214, 218, 276, 242, 486, 323, 228, 490, 477, 432, 128, 392, 338, 420, 90, 172, 182, 566, 43, 423, 487, 788, 125, 471, 377, 623, 160, 978, 268, 168, 40, 223, 487, 170, 466, 308, 174, 399, 448, 235, 534, 660, 238, 273, 416, 223, 234, 458, 273, 310, 365, 188, 289, 167, 84, 434, 230, 534, 658, 526, 182, 965, 516, 288, 1070, 391, 631, 689, 162, 295, 380, 217, 258, 153, 239, 106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n",
      "done\n",
      "51988\n",
      "init\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch_tokens1 = batch_tokens1.to(device)\n",
    "    prots_lengths = [len(prot[1]) for prot in data2]\n",
    "    print(prots_lengths)\n",
    "    output2 = sparse_model(input_ids=batch_tokens1, output_attentions = True, two_step_selection= True, proteins_sizes = torch.tensor(prots_lengths))\n",
    "\n",
    "# Very long (approx 3h for 52k genome) - due to import number of pairs \n",
    "# Returns the dictionnary of protein pairs with score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Pair Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014, 174, 306, 296, 299, 85, 240, 466, 388, 374, 492, 490, 65, 391, 236, 471, 291, 644, 200, 103, 609, 85, 145, 142, 66, 430, 463, 515, 573, 433, 461, 210, 157, 72, 420, 314, 270, 67, 383, 437, 390, 338, 283, 114, 350, 390, 113, 799, 215, 308, 311, 494, 131, 298, 330, 537, 152, 449, 339, 308, 322, 301, 593, 41, 140, 483, 416, 225, 463, 173, 326, 477, 185, 144, 125, 475, 214, 218, 276, 242, 486, 323, 228, 490, 477, 432, 128, 392, 338, 420, 90, 172, 182, 566, 43, 423, 487, 788, 125, 471, 377, 623, 160, 978, 268, 168, 40, 223, 487, 170, 466, 308, 174, 399, 448, 235, 534, 660, 238, 273, 416, 223, 234, 458, 273, 310, 365, 188, 289, 167, 84, 434, 230, 534, 658, 526, 182, 965, 516, 288, 1070, 391, 631, 689, 162, 295, 380, 217, 258, 153, 239, 106]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch_tokens1 = batch_tokens1.to(device)\n",
    "    prots_lengths = [len(prot[1]) for prot in data2]\n",
    "    prot_int = [1, 2]\n",
    "    print(prots_lengths)\n",
    "    output3 = sparse_model(input_ids=batch_tokens1, output_attentions = True, two_step_selection= False, proteins_sizes = torch.tensor(prots_lengths), proteins_interactions = torch.tensor(prot_int))\n",
    "\n",
    "# Approx 1m50 to run for the 52k genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_attention(attentions: Tuple[torch.Tensor, ...], weight_scheme: List[float]) -> torch.Tensor:\n",
    "    x,y,n1,n2 = len(attentions), attentions[0][0].shape[0], attentions[0][0].shape[1], attentions[0][0].shape[2]\n",
    "    assert len(weight_scheme) == x * y\n",
    "    \n",
    "    weighted_sum = torch.zeros_like(attentions[0][0][0])\n",
    "\n",
    "    stacked_attentions = torch.stack(attentions, dim=0)\n",
    "    weights = torch.tensor(weight_scheme, dtype=stacked_attentions.dtype, device=stacked_attentions.device)\n",
    "\n",
    "    flattened_attentions = stacked_attentions.view(x * y, n1, n2)\n",
    "    weighted_sum = torch.sum(flattened_attentions * weights[:, None, None], dim=0)\n",
    "    \n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 torch.Size([1, 20, 174, 306])\n",
      "torch.Size([174, 306])\n"
     ]
    }
   ],
   "source": [
    "print(len(output3.attentions), output3.attentions[0].shape)\n",
    "weight_scheme = [1]*(len(output3.attentions)*output3.attentions[0][0].shape[0]) # num_layers * num_heads\n",
    "print(compute_combined_attention(output3.attentions,weight_scheme).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
